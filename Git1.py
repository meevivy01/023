import time
import pandas as pd
import undetected_chromedriver as uc
import os
import datetime
import re
import random
import yaml
import json
import smtplib
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.image import MIMEImage
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from dotenv import load_dotenv
from thefuzz import fuzz 
from dateutil.relativedelta import relativedelta 
import logging
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, BarColumn, TextColumn, TimeRemainingColumn, TimeElapsedColumn, TaskProgressColumn
from rich.theme import Theme

# --- SETUP & CONFIG ---
try:
    from fake_useragent import UserAgent
except ImportError:
    UserAgent = None

logging.getLogger("fake_useragent").setLevel(logging.CRITICAL)

def suppress_del_error(self):
    try: self.quit()
    except Exception: pass
uc.Chrome.__del__ = suppress_del_error

ENV_PATH = "User.env"
COMPETITORS_PATH = "compe.yaml"
CLIENTS_PATH = "co.yaml"
TIER1_PATH = "tier1.yaml"
RESUME_IMAGE_FOLDER = "resume_images" 
USE_HEADLESS_JOBTHAI = True 
EMAIL_USE_HISTORY = False       

rec_env = os.getenv("EMAIL_RECEIVER")
MANUAL_EMAIL_RECEIVERS = [rec_env] if rec_env else []

custom_theme = Theme({"info": "dim cyan", "warning": "yellow", "error": "bold red", "success": "bold green"})
console = Console(theme=custom_theme)

load_dotenv(ENV_PATH, override=True)
MY_USERNAME = os.getenv("JOBTHAI_USER")
MY_PASSWORD = os.getenv("JOBTHAI_PASS")

G_SHEET_KEY_JSON = os.getenv("G_SHEET_KEY")
G_SHEET_NAME = os.getenv("G_SHEET_NAME")

TIER1_TARGETS = {}
if os.path.exists(TIER1_PATH):
    try:
        with open(TIER1_PATH, "r", encoding="utf-8") as f:
            yaml_data = yaml.safe_load(f)
            if yaml_data:
                for k, v in yaml_data.items():
                    if v:
                        if isinstance(v, list):
                            TIER1_TARGETS[k] = [str(x).strip() for x in v]
                        else:
                            TIER1_TARGETS[k] = [str(v).strip()]
    except Exception as e:
        console.print(f"‚ö†Ô∏è Load Tier1 Error: {e}", style="yellow")

TARGET_COMPETITORS_TIER2 = [] 
if os.path.exists(COMPETITORS_PATH):
    try:
        with open(COMPETITORS_PATH, "r", encoding="utf-8") as f:
            yaml_data = yaml.safe_load(f)
            if yaml_data and 'competitors' in yaml_data:
                TARGET_COMPETITORS_TIER2 = [str(x).strip() for x in yaml_data['competitors'] if x]
    except: pass

CLIENTS_TARGETS = {}
if os.path.exists(CLIENTS_PATH):
    try:
        with open(CLIENTS_PATH, "r", encoding="utf-8") as f:
            CLIENTS_TARGETS = yaml.safe_load(f) or {}
            for k in list(CLIENTS_TARGETS.keys()):
                if not CLIENTS_TARGETS[k]: del CLIENTS_TARGETS[k]
                elif not isinstance(CLIENTS_TARGETS[k], list): CLIENTS_TARGETS[k] = [str(CLIENTS_TARGETS[k])]
    except: pass

TARGET_UNIVERSITIES = ["‡∏ô‡πÄ‡∏£‡∏®‡∏ß‡∏£", "‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢‡∏ô‡πÄ‡∏£‡∏®‡∏ß‡∏£" , "Naresuan University"]  
TARGET_FACULTIES = ["‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á","Cosmetic Science"] 
TARGET_MAJORS = ["‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á", "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á","Cosmetic Science", "Cosmetics", "Cosmetic"]
SEARCH_KEYWORDS = ["‡∏ô‡πÄ‡∏£‡∏®‡∏ß‡∏£ ‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏≥‡∏≠‡∏≤‡∏á"]

KEYWORDS_CONFIG = {
    "NPD": {"titles": ["NPD", "R&D", "RD", "Research", "Development", "‡∏ß‡∏¥‡∏à‡∏±‡∏¢", "‡∏û‡∏±‡∏í‡∏ô‡∏≤", "Formulation", "‡∏™‡∏π‡∏ï‡∏£"]},
    "PCM": {"titles": ["PCM", "Production", "‡∏ú‡∏•‡∏¥‡∏ï", "Manufacturing", "Factory", "‡πÇ‡∏£‡∏á‡∏á‡∏≤‡∏ô", "QA", "QC"]},
    "Sales": {"titles": ["Sale", "Sales", "‡∏Ç‡∏≤‡∏¢", "AE", "BD", "Customer", "Telesale"]},
    "MKT": {"titles": ["MKT", "Marketing", "‡∏Å‡∏≤‡∏£‡∏ï‡∏•‡∏≤‡∏î", "Digital", "Content", "Media", "Ads"]},
    "Admin": {"titles": ["Admin", "‡∏ò‡∏∏‡∏£‡∏Å‡∏≤‡∏£", "‡∏õ‡∏£‡∏∞‡∏™‡∏≤‡∏ô‡∏á‡∏≤‡∏ô", "Coordinator", "Document", "‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£"]},
    "HR": {"titles": ["HR", "Recruit", "‡∏™‡∏£‡∏£‡∏´‡∏≤", "‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•", "Training", "Payroll"]},
    "SCM": {"titles": ["SCM", "Supply Chain", "Logistic", "‡∏Ç‡∏ô‡∏™‡πà‡∏á", "Warehouse", "Stock", "Import", "Export"]},
    "PUR": {"titles": ["PUR", "Purchase", "‡∏à‡∏±‡∏î‡∏ã‡∏∑‡πâ‡∏≠", "Sourcing", "Buyer"]},
    "DATA": {"titles": ["Data", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "Analyst", "Statistic", "‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥"]},
    "Present": {"titles": ["Present", "Speaker", "‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏£", "Trainer"]},
    "IT": {"titles": ["IT", "Computer", "Software", "Programmer", "Developer"]},
    "RA": {"titles": ["RA", "Regulatory", "‡∏≠‡∏¢.", "FDA", "‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô"]},
    "ACC": {"titles": ["ACC", "Account", "‡∏ö‡∏±‡∏ç‡∏ä‡∏µ", "Finance", "‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô", "Audit"]}
}

def analyze_row_department(row):
    scores = {dept: 0 for dept in KEYWORDS_CONFIG.keys()}
    target_cols = ['‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_1', '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_2', '‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_3']
    for col in target_cols:
        if col not in row or pd.isna(row[col]): continue
        text_val = str(row[col]).lower()
        for dept, config in KEYWORDS_CONFIG.items():
            for keyword in config['titles']:
                if keyword.lower() in text_val:
                    scores[dept] += 33
                    break 
    if not scores: return pd.Series(["Uncategorized", 0, ""])
    sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)
    best_dept, max_score = sorted_scores[0]
    return pd.Series([best_dept, int(min(max_score, 100)), ", ".join([f"{k}({v})" for k, v in sorted_scores if v > 0])])

class JobThaiRowScraper:
    def __init__(self):
        console.rule("[bold cyan]üîß JobThai Scraper (Google Sheets Edition)...[/]")
        self.history_file = "notification_history_uni.json" 
        self.history_data = {}
        if not os.path.exists(RESUME_IMAGE_FOLDER): os.makedirs(RESUME_IMAGE_FOLDER, exist_ok=True)
        
        if EMAIL_USE_HISTORY and os.path.exists(self.history_file):
            try:
                with open(self.history_file, 'r', encoding='utf-8') as f: self.history_data = json.load(f)
            except: self.history_data = {}

        if UserAgent: self.ua = UserAgent(browsers=['chrome'], os=['windows', 'macos'])
        else: self.ua = None

        opts = uc.ChromeOptions()
        opts.add_argument('--headless=new') 
        opts.add_argument('--window-size=1920,1080')
        opts.add_argument("--no-sandbox")
        opts.add_argument("--disable-dev-shm-usage")
        opts.add_argument("--disable-popup-blocking")
        
        # üü¢ [‡πÄ‡∏û‡∏¥‡πà‡∏° 1] ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ô‡πÑ‡∏ó‡∏¢ (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡πÄ‡∏°‡∏∑‡∏≠‡∏á‡∏ô‡∏≠‡∏Å)
        opts.add_argument("--lang=th-TH")
        
        # üü¢ [‡πÄ‡∏û‡∏¥‡πà‡∏° 2] ‡∏õ‡∏¥‡∏î‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏ó‡∏ä‡∏≠‡∏ö‡πÉ‡∏ä‡πâ
        opts.add_argument("--disable-blink-features=AutomationControlled")
        opts.add_argument("--disable-notifications")
        
        fake_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        opts.add_argument(f'--user-agent={fake_user_agent}')
        
        try: self.driver = uc.Chrome(options=opts, use_subprocess=True)
        except: self.driver = uc.Chrome(options=opts, use_subprocess=True)
        self.wait = WebDriverWait(self.driver, 20)
        self.total_profiles_viewed = 0 
        
        self.all_scraped_data = []

    def save_history(self):
        if not EMAIL_USE_HISTORY: return
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f: json.dump(self.history_data, f, ensure_ascii=False, indent=4)
        except: pass

    def set_random_user_agent(self):
        if self.ua:
            try: self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {"userAgent": self.ua.random})
            except: pass

    def random_sleep(self, min_t=4.0, max_t=7.0): time.sleep(random.uniform(min_t, max_t))

    # üü¢ [‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà] ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏° ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏ô‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏ß‡∏≤‡∏î‡∏™‡∏≤‡∏¢‡∏ï‡∏≤
    # üü¢ ‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏ß‡∏≤‡∏á‡πÉ‡∏ô Class JobThaiRowScraper
    def human_scroll(self):
        try:
            # ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
            total_height = self.driver.execute_script("return document.body.scrollHeight")
            
            # ‡∏Ñ‡πà‡∏≠‡∏¢‡πÜ ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏•‡∏á‡∏°‡∏≤‡∏ó‡∏µ‡∏•‡∏∞‡∏ô‡∏¥‡∏î ‡πÅ‡∏ö‡∏ö‡∏™‡∏∏‡πà‡∏°‡∏£‡∏∞‡∏¢‡∏∞ (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏ô‡πÄ‡∏≠‡∏≤‡∏ô‡∏¥‡πâ‡∏ß‡πÑ‡∏ñ‡∏°‡∏∑‡∏≠‡∏ñ‡∏∑‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏°‡∏∏‡∏ô Mouse wheel)
            current_position = 0
            while current_position < total_height:
                scroll_step = random.randint(300, 700) # ‡∏™‡∏∏‡πà‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô
                current_position += scroll_step
                self.driver.execute_script(f"window.scrollTo(0, {current_position});")
                time.sleep(random.uniform(0.1, 0.4)) # ‡∏´‡∏¢‡∏∏‡∏î‡∏ô‡∏¥‡∏î‡∏ô‡∏∂‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô
            
            # ‡∏û‡∏≠‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏™‡∏∏‡∏î‡πÅ‡∏•‡πâ‡∏ß ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡∏Ç‡∏∂‡πâ‡∏ô‡πÑ‡∏õ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô‡∏™‡∏∏‡∏î (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ JobThai ‡πÇ‡∏´‡∏•‡∏î Header ‡∏Ñ‡∏£‡∏ö)
            time.sleep(0.5)
            self.driver.execute_script("window.scrollTo(0, 0);")
        except Exception as e:
            pass # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡πá‡∏ä‡πà‡∏≤‡∏á‡∏°‡∏±‡∏ô ‡πÑ‡∏õ‡∏ï‡πà‡∏≠‡πÄ‡∏•‡∏¢

    def parse_thai_date_exact(self, date_str):
        if not date_str: return None
        thai_months = {'‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': 1, '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': 2, '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': 3, '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': 4, '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': 5, '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': 6, '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': 7, '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': 8, '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': 9, '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': 10, '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': 11, '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': 12}
        try:
            date_str = date_str.strip()
            parts = date_str.split() 
            if len(parts) < 3: return None
            day = int(parts[0])
            month = thai_months.get(parts[1])
            year_be = int(parts[2])
            year_ad = year_be - 543
            return datetime.date(year_ad, month, day)
        except: return None

    def calculate_duration_text(self, date_range_str):
        if not date_range_str: return ""
        thai_months = {'‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': 1, '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': 2, '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': 3, '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': 4, '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': 5, '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': 6, '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': 7, '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': 8, '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': 9, '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': 10, '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': 11, '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': 12}
        try:
            clean_str = " ".join(date_range_str.split())
            if '-' not in clean_str: return ""
            start_str, end_str = clean_str.split('-')
            def parse_thai_date(d_str):
                d_str = d_str.strip()
                if "‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô" in d_str: return datetime.datetime.now()
                parts = d_str.split()
                if len(parts) < 2: return None
                m = thai_months.get(parts[0])
                if not m: return None
                y = int(parts[1]) - 543
                return datetime.datetime(y, m, 1)
            s_date = parse_thai_date(start_str)
            e_date = parse_thai_date(end_str)
            if s_date and e_date:
                diff = relativedelta(e_date, s_date)
                txt = []
                if diff.years > 0: txt.append(f"{diff.years} ‡∏õ‡∏µ")
                if diff.months > 0: txt.append(f"{diff.months} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
                return " ".join(txt) if txt else "‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 1 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô"
            return ""
        except: return ""

    def step1_login(self):
        cookies_env = os.getenv("COOKIES_JSON")
        if cookies_env:
            console.print("üç™ ‡πÉ‡∏ä‡πâ Cookie Bypass...", style="bold green")
            try:
                self.driver.get("https://www.jobthai.com/th/employer")
                time.sleep(2)
                cookies_list = json.loads(cookies_env)
                for cookie in cookies_list:
                    c = {k: v for k, v in cookie.items() if k in ['name', 'value', 'domain', 'path', 'expiry', 'secure', 'httpOnly']}
                    try: self.driver.add_cookie(c)
                    except: pass
                self.driver.refresh()
                time.sleep(5)
                self.driver.get("https://www3.jobthai.com/findresume/findresume.php?l=th")
                time.sleep(3)
                if "login" not in self.driver.current_url:
                    console.print("üéâ Login Bypass ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!", style="success")
                    return True
            except Exception as e: console.print(f"‚ùå Cookie Error: {e}", style="error")

        login_url = "https://www.jobthai.com/th/employer"
        console.print("1Ô∏è‚É£   ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏´‡∏ô‡πâ‡∏≤ Login (Direct)...", style="info")
        try:
            self.driver.get(login_url)
            self.random_sleep(3, 5)
            
            if len(self.driver.find_elements(By.TAG_NAME, "iframe")) > 0:
                console.print("   üëÄ ‡∏û‡∏ö Iframe (‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á Cloudflare)", style="warning")

            try:
                user_input = WebDriverWait(self.driver, 20).until(EC.visibility_of_element_located((By.CSS_SELECTOR, "input[name='username']")))
                pass_input = self.driver.find_element(By.CSS_SELECTOR, "input[type='password']")
            except:
                console.print("‚ùå ‡∏´‡∏≤‡∏ä‡πà‡∏≠‡∏á‡∏Å‡∏£‡∏≠‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠", style="error")
                return False

            if user_input and pass_input:
                user_input.clear(); user_input.send_keys(MY_USERNAME)
                pass_input.clear(); pass_input.send_keys(MY_PASSWORD)
                pass_input.send_keys(Keys.ENTER)
                for _ in range(30):
                    time.sleep(1)
                    if "auth.jobthai.com" not in self.driver.current_url and "login" not in self.driver.current_url:
                        console.print("‚úÖ Login ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!", style="success")
                        return True
            return False
        except Exception as e:
            console.print(f"‚ùå Login Failed: {e}", style="error")
            return False

    def step2_search(self, keyword):
        search_url = "https://www3.jobthai.com/findresume/findresume.php?l=th"
        console.print(f"2Ô∏è‚É£   ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏û‡∏¥‡∏°‡∏û‡πå: '[bold]{keyword}[/]' ...", style="info")
        try:
            self.driver.get(search_url)
            self.random_sleep(7, 10) 
            keyword_input = WebDriverWait(self.driver, 20).until(EC.visibility_of_element_located((By.ID, "KeyWord")))
            keyword_input.clear()
            time.sleep(0.5)
            keyword_input.send_keys(keyword)
            time.sleep(1)
            search_btn = self.driver.find_element(By.ID, "buttonsearch")
            try: search_btn.click()
            except: self.driver.execute_script("arguments[0].click();", search_btn)
            
            try:
                WebDriverWait(self.driver, 10).until(lambda d: "KeyWord" in d.current_url or "ResumeDetail" in d.page_source)
                return True
            except:
                keyword_input.send_keys(Keys.ENTER)
                time.sleep(5)
                if "KeyWord" in self.driver.current_url: return True
                return False
        except Exception as e:
            console.print(f"‚ùå Search Error ({keyword}): {e}", style="error")
            return False

    def step3_collect_all_links(self):
        collected_links = []
        page_num = 1
        console.rule("[bold yellow]3Ô∏è‚É£  ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏Å‡πá‡∏ö‡∏•‡∏¥‡∏á‡∏Å‡πå[/]")
        
        while True:
            console.print(f"   üìÑ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà {page_num}...", style="info")
            try:
                xpath_resume = "//a[contains(@href, 'ResumeDetail') or contains(@href, '/resume/')]"
                try: WebDriverWait(self.driver, 5).until(EC.presence_of_element_located((By.XPATH, xpath_resume)))
                except: pass 
                
                all_anchors = self.driver.find_elements(By.XPATH, xpath_resume)
                
                count_before = len(collected_links)
                for a in all_anchors:
                    try:
                        href = a.get_attribute("href")
                        if href and href not in collected_links:
                            collected_links.append(href)
                    except: continue
                
                new_count = len(collected_links) - count_before
                console.print(f"      -> ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÑ‡∏î‡πâ: {new_count} ‡∏•‡∏¥‡∏á‡∏Å‡πå (‡∏£‡∏ß‡∏° {len(collected_links)})", style="success")

            except Exception as e:
                console.print(f"      ‚ùå Error ‡∏ï‡∏≠‡∏ô‡∏´‡∏≤‡∏•‡∏¥‡∏á‡∏Å‡πå: {e}", style="error")

            if len(collected_links) == 0: break
            if new_count == 0: break

            try:
                next_btn_xpath = '//*[@id="content-l"]/div[2]/div[1]/table/tbody/tr/td[8]/a'
                next_btns = self.driver.find_elements(By.XPATH, next_btn_xpath)
                if next_btns and next_btns[0].is_displayed():
                    self.driver.execute_script("arguments[0].click();", next_btns[0])
                    page_num += 1
                    time.sleep(3)
                else: break
            except: break
            
        console.print(f"[bold green]üì¶ ‡∏™‡∏£‡∏∏‡∏õ‡∏¢‡∏≠‡∏î‡∏£‡∏ß‡∏°: {len(collected_links)} ‡∏•‡∏¥‡∏á‡∏Å‡πå[/]")
        return collected_links

    def scrape_detail_from_json(self, url, keyword, progress_console=None):
        printer = progress_console if progress_console else console
        self.set_random_user_agent()
        
        max_retries = 3
        load_success = False
        for attempt in range(max_retries):
            try:
                self.driver.get(url)
                load_success = True
                break 
            except: self.random_sleep(5, 10)

        if not load_success: return None, 999, None
        
        # üü¢ [‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ï‡∏¥‡∏°] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏£‡∏±‡∏ö üü¢
        # ‡πÅ‡∏Å‡∏•‡πâ‡∏á‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Human Behavior)
        try:
            self.human_scroll() 
        except: 
            pass # ‡∏Å‡∏±‡∏ô‡πÄ‡∏´‡∏ô‡∏µ‡∏¢‡∏ß‡πÑ‡∏ß‡πâ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏Å‡πá‡∏≠‡∏¢‡πà‡∏≤‡πÉ‡∏´‡πâ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏û‡∏±‡∏á
            
        self.random_sleep(2.0, 5.0) # ‡∏£‡∏≠‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡∏™‡∏±‡∏Å‡∏û‡∏±‡∏Å
        # üü¢ [‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏¥‡∏°] üü¢
        
        data = {'Link': url}
        try: full_text = self.driver.find_element(By.CSS_SELECTOR, "#mainTableTwoColumn").text
        except: full_text = ""
        
        # ... (‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏õ‡πä‡∏∞) ...
        
        def get_val(sel, xpath=False):
            try:
                elem = self.driver.find_element(By.XPATH, sel) if xpath else self.driver.find_element(By.CSS_SELECTOR, sel)
                return elem.text.strip()
            except: return ""

        edu_tables_xpath = '//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[7]/td[2]/table'
        try:
            edu_tables = self.driver.find_elements(By.XPATH, edu_tables_xpath)
            total_degrees = len(edu_tables)
        except: total_degrees = 0
        matched_uni = ""; matched_faculty = ""; matched_major = ""; is_qualified = False
        highest_degree_text = "-"; max_degree_score = -1
        degree_score_map = {"‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÄ‡∏≠‡∏Å": 3, "‡∏î‡∏∏‡∏©‡∏é‡∏µ‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï": 3, "Doctor": 3, "Ph.D": 3, "‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó": 2, "‡∏°‡∏´‡∏≤‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï": 2, "Master": 2, "‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ": 1, "‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï": 1, "Bachelor": 1}
        def check_fuzzy(scraped_text, target_list, threshold=95):
            if not target_list: return True
            if not scraped_text: return False
            best_score = 0
            for target in target_list:
                score = fuzz.partial_ratio(target.lower(), scraped_text.lower())
                if score > best_score: best_score = score
            if best_score >= threshold: return True
            return False 

        for i in range(1, total_degrees + 1):
            base_xpath = f'//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[7]/td[2]/table[{i}]'
            curr_uni = get_val(f'{base_xpath}/tbody/tr[2]/td/div', True)
            if not curr_uni: curr_uni = get_val(f'{base_xpath}/tbody/tr[1]/td/div', True)
            curr_degree = get_val(f'{base_xpath}//td[contains(., "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤")]/following-sibling::td[1]', True)
            if not curr_degree: curr_degree = get_val(f'{base_xpath}/tbody/tr[1]/td', True)
            curr_faculty = get_val(f'{base_xpath}//td[contains(., "‡∏Ñ‡∏ì‡∏∞")]/following-sibling::td[1]', True)
            curr_major = get_val(f'{base_xpath}//td[contains(., "‡∏™‡∏≤‡∏Ç‡∏≤")]/following-sibling::td[1]', True)
            
            score = 0
            for key, val in degree_score_map.items():
                if key in str(curr_degree): score = val; break
            if score > max_degree_score: max_degree_score = score; highest_degree_text = curr_degree
            elif score == max_degree_score and highest_degree_text == "-": highest_degree_text = curr_degree

            if not is_qualified:
                uni_pass = check_fuzzy(curr_uni, TARGET_UNIVERSITIES)
                fac_pass = check_fuzzy(curr_faculty, TARGET_FACULTIES)
                major_pass = check_fuzzy(curr_major, TARGET_MAJORS)
                if uni_pass and (fac_pass or major_pass):
                    is_qualified = True; matched_uni = curr_uni; matched_faculty = curr_faculty; matched_major = curr_major

        if not is_qualified: return None, 999, None
        
        data['‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤'] = highest_degree_text; data['‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢'] = matched_uni; data['‡∏Ñ‡∏ì‡∏∞'] = matched_faculty; data['‡∏™‡∏≤‡∏Ç‡∏≤'] = matched_major
        data['‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£'] = get_val("#ResumeViewDiv [align='left'] span.white")
        
        try:
            img_element = self.driver.find_element(By.ID, "DefaultPictureResume2Column")
            app_id_clean = data['‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£'].strip() if data['‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£'] else f"unknown_{int(time.time())}"
            img_filename = f"{app_id_clean}.png"
            save_path = os.path.join(RESUME_IMAGE_FOLDER, img_filename)
            img_element.screenshot(save_path)
            data['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'] = save_path
        except: data['‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û'] = ""

        # üü¢ [FIXED] ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ) ‡∏ô‡∏≥‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö
        raw_update_date = get_val('//*[@id="ResumeViewDiv"]/table/tbody/tr[2]/td[3]/span[2]', xpath=True)
        
        def calculate_last_update(date_str):
            if not date_str: return "-"
            try:
                parts = date_str.split()
                if len(parts) < 3: return "-"
                day = int(parts[0])
                month_str = parts[1]
                year_be = int(parts[2])
                year_ad = year_be - 543
                thai_months = {'‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°': 1, '‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå': 2, '‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°': 3, '‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô': 4, '‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°': 5, '‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô': 6, '‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°': 7, '‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°': 8, '‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô': 9, '‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°': 10, '‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô': 11, '‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°': 12}
                month = thai_months.get(month_str, 1)
                update_dt = datetime.datetime(year_ad, month, day)
                diff = relativedelta(datetime.datetime.now(), update_dt)
                txt = []
                if diff.years > 0: txt.append(f"{diff.years}‡∏õ‡∏µ")
                if diff.months > 0: txt.append(f"{diff.months}‡πÄ‡∏î‡∏∑‡∏≠‡∏ô")
                if diff.days > 0: txt.append(f"{diff.days}‡∏ß‡∏±‡∏ô")
                if not txt: return "‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ"
                return " ".join(txt)
            except: return "-"
            
        data['‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î'] = calculate_last_update(raw_update_date) # ‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡πâ‡∏ß

        data['‡∏ä‡∏∑‡πà‡∏≠'] = get_val("#mainTableTwoColumn td > span.head1")
        data['‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•'] = get_val("span.black:nth-of-type(3)")
        age_match = re.search(r"‡∏≠‡∏≤‡∏¢‡∏∏\s*[:]?\s*(\d+)", full_text)
        data['‡∏≠‡∏≤‡∏¢‡∏∏'] = age_match.group(1) if age_match else ""
        data['‡πÄ‡∏û‡∏®'] = re.search(r"‡πÄ‡∏û‡∏®\s*[:]?\s*(‡∏ä‡∏≤‡∏¢|‡∏´‡∏ç‡∏¥‡∏á|Male|Female)", full_text).group(1) if re.search(r"‡πÄ‡∏û‡∏®\s*[:]?\s*(‡∏ä‡∏≤‡∏¢|‡∏´‡∏ç‡∏¥‡∏á|Male|Female)", full_text) else ""
        data['‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£'] = get_val("#mainTableTwoColumn div:nth-of-type(6) span.black")
        data['Email'] = get_val("#mainTableTwoColumn a")
        data['‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà'] = get_val("#mainTableTwoColumn div:nth-of-type(1) span.head1")
        data['‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà'] = get_val("#mainTableTwoColumn table [width][align='left'] div span.headNormal")
        
        pos1 = get_val('//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[5]/td[2]/table/tbody/tr[3]/td/span[2]', xpath=True)
        pos2 = get_val('//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[5]/td[2]/table/tbody/tr[3]/td/span[4]', xpath=True)
        pos3 = get_val('//*[@id="mainTableTwoColumn"]/tbody/tr/td[1]/table/tbody/tr[5]/td[2]/table/tbody/tr[3]/td/span[6]', xpath=True)
        data['‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_1'] = pos1; data['‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_2'] = pos2; data['‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_3'] = pos3
        combined_positions = ", ".join([p for p in [pos1, pos2, pos3] if p])
        data['‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£'] = get_val("//td[contains(., '‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£')]/following-sibling::td[1]", True)
        
        # üü¢ [FIXED] ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏¢‡∏Å‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏´‡πâ‡∏ï‡∏∞‡∏Å‡∏µ‡πâ)
        salary_min_txt = "-"
        salary_max_txt = "-"
        raw_salary = data.get('‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£', '')
        try:
            if raw_salary and '‡∏õ‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•' not in str(raw_salary):
                s = str(raw_salary).lower().replace(',', '')
                s = re.sub(r'(\d+(\.\d+)?)\s*k', lambda m: str(float(m.group(1)) * 1000), s)
                nums = re.findall(r'\d+(?:\.\d+)?', s)
                nums = [float(n) for n in nums]
                if nums:
                    mn, mx = nums[0], nums[0]
                    if len(nums) >= 2: mn, mx = nums[0], nums[1]
                    if mx > 1000 and mn < 1000 and mn > 0: mn *= 1000
                    salary_min_txt = f"{int(mn):,}"
                    salary_max_txt = f"{int(mx):,}"
        except: pass
        
        data['Salary_Min'] = salary_min_txt
        data['Salary_Max'] = salary_max_txt

        all_work_history = []
        try:
            if "‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô/‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô" in full_text:
                history_text = full_text.split("‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô/‡∏ù‡∏∂‡∏Å‡∏á‡∏≤‡∏ô")[1].split("‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ")[0]
            else: history_text = ""
            thai_months_str = "‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå|‡∏°‡∏µ‡∏ô‡∏≤‡∏Ñ‡∏°|‡πÄ‡∏°‡∏©‡∏≤‡∏¢‡∏ô|‡∏û‡∏§‡∏©‡∏†‡∏≤‡∏Ñ‡∏°|‡∏°‡∏¥‡∏ñ‡∏∏‡∏ô‡∏≤‡∏¢‡∏ô|‡∏Å‡∏£‡∏Å‡∏é‡∏≤‡∏Ñ‡∏°|‡∏™‡∏¥‡∏á‡∏´‡∏≤‡∏Ñ‡∏°|‡∏Å‡∏±‡∏ô‡∏¢‡∏≤‡∏¢‡∏ô|‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°|‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô|‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°"
            raw_chunks = re.split(f"({thai_months_str})\\s+\\d{{4}}\\s+-\\s+", history_text)
            jobs = []
            if len(raw_chunks) > 1:
                for k in range(1, len(raw_chunks), 2):
                    if k+1 < len(raw_chunks): jobs.append(raw_chunks[k] + raw_chunks[k+1]) 
            i = 0
            while True:
                check_xpath = f'//*[@id="mainTableTwoColumn"]/tbody/tr/td[2]/table/tbody/tr[2]/td[2]/table[{i+1}]'
                try:
                    if len(self.driver.find_elements(By.XPATH, check_xpath)) == 0: break
                except: break
                suffix = f"_{i+1}"
                company = get_val(f'{check_xpath}/tbody/tr[3]/td/div/span', True)
                if not company: company = get_val(f'{check_xpath}/tbody/tr[3]/td', True)
                if i < len(jobs):
                    block = jobs[i]
                    if not company:
                        comp_match = re.search(r"^.*(‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó|Ltd|Inc|Group|Organization|‡∏´‡∏à‡∏Å|Limited).*$", block, re.MULTILINE | re.IGNORECASE)
                        company = comp_match.group(0).strip() if comp_match else ""
                data[f'‡∏ä‡∏∑‡πà‡∏≠‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô{suffix}'] = company
                if company: all_work_history.append(company.strip())
                i += 1
        except: pass
        
        competitor_str = ", ".join(all_work_history)
        data['‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á'] = competitor_str

        # ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏≠‡∏≤‡∏¢‡∏∏ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Logic ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡πÇ‡∏ä‡∏ß‡πå)
        today_date = datetime.date.today()
        update_date = self.parse_thai_date_exact(raw_update_date) # ‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ö‡∏°‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Diff (‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß)
        days_diff = 999
        if update_date: days_diff = (today_date - update_date).days

        app_id = data.get('‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£', '').strip()
        full_name = f"{data.get('‡∏ä‡∏∑‡πà‡∏≠', '')} {data.get('‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•', '')}"
        
        person_data = {
            "keyword": keyword, 
            "company": competitor_str,
            "degree": highest_degree_text,
            "salary_min": salary_min_txt,
            "salary_max": salary_max_txt,
            "id": app_id,
            "name": full_name,
            "age": data.get('‡∏≠‡∏≤‡∏¢‡∏∏', '-'),
            "positions": combined_positions, 
            "last_update": data['‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î'], # üü¢ ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡πÇ‡∏ä‡∏ß‡πå‡πÄ‡∏õ‡πá‡∏ô '2 ‡∏ß‡∏±‡∏ô' ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏•‡πâ‡∏ß
            "link": url,
            "image_path": data.get('‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û', '')
        }

        printer.print(f"   üî• ‡πÄ‡∏à‡∏≠: {highest_degree_text} | ‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢: {matched_uni} | ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {days_diff} ‡∏ß‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô", style="bold green")
        return data, days_diff, person_data
    
    def send_single_email(self, subject_prefix, people_list, col_header="‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó"):
        sender = os.getenv("EMAIL_SENDER")
        password = os.getenv("EMAIL_PASSWORD")
        receiver_list = []
        if MANUAL_EMAIL_RECEIVERS and len(MANUAL_EMAIL_RECEIVERS) > 0: receiver_list = MANUAL_EMAIL_RECEIVERS
        else:
             rec_env = os.getenv("EMAIL_RECEIVER")
             if rec_env: receiver_list = [rec_env]
        
        if not sender or not password or not receiver_list: return

        # Logic ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏°‡∏•
        if "‡∏™‡∏£‡∏∏‡∏õ" in subject_prefix or "HOT" in subject_prefix: subject = subject_prefix
        elif len(people_list) > 1: subject = f"üî• {subject_prefix} ({len(people_list)} ‡∏Ñ‡∏ô)"
        else: subject = subject_prefix 

        body_html = f"""
        <html>
        <head>
        <style>
            table {{ border-collapse: collapse; width: 100%; font-size: 14px; }}
            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
            th {{ background-color: #f2f2f2; }}
            tr:nth-child(even) {{ background-color: #f9f9f9; }}
            .btn {{
                background-color: #28a745; 
                color: #ffffff !important; 
                padding: 5px 10px;
                text-align: center; 
                text-decoration: none; 
                display: inline-block;
                border-radius: 4px; 
                font-size: 12px;
                font-weight: bold;
            }}
            .btn:hover, .btn:visited, .btn:active {{ color: #ffffff !important; }}
        </style>
        </head>
        <body>
            <h3>{subject}</h3>
            <table>
                <tr>
                    <th style="width: 10%;">‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û</th>
                    <th style="width: 15%;">{col_header}</th>
                    <th style="width: 10%;">‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î</th>
                    <th style="width: 10%;">‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£</th>
                    <th style="width: 15%;">‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•</th>
                    <th style="width: 5%;">‡∏≠‡∏≤‡∏¢‡∏∏</th>
                    <th style="width: 15%;">‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏±‡∏Ñ‡∏£</th>
                    <th style="width: 8%;">‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥</th> <th style="width: 8%;">‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î</th> <th style="width: 10%;">‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î</th>
                    <th style="width: 10%;">‡∏•‡∏¥‡∏á‡∏Å‡πå</th>
                </tr>
        """
        
        images_to_attach = []
        for person in people_list:
            cid_id = f"img_{person['id']}"
            if person['image_path'] and os.path.exists(person['image_path']):
                img_html = f'<img src="cid:{cid_id}" width="80" style="border-radius: 5px;">'
                images_to_attach.append({'cid': cid_id, 'path': person['image_path']})
            else:
                img_html = '<span style="color:gray;">No Image</span>'

            company_display = person['company']
            if company_display == "University Target" or company_display == "-":
                company_display = "-"
                company_style = "font-weight: bold;" 
            else:
                company_style = "font-weight: normal;"

            body_html += f"""
                <tr>
                    <td style="text-align: center;">{img_html}</td>
                    <td style="{company_style}">{company_display}</td>
                    <td>{person.get('degree', '-')}</td> 
                    <td>{person['id']}</td>
                    <td>{person['name']}</td>
                    <td>{person['age']}</td>
                    <td>{person['positions']}</td>
                    <td>{person.get('salary_min', '-')}</td> <td>{person.get('salary_max', '-')}</td> <td>{person['last_update']}</td>
                    <td style="text-align: center;">
                        <a href="{person['link']}" target="_blank" class="btn" style="color: #ffffff; text-decoration: none;">‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡∏π</a>
                    </td>
                </tr>
            """
            
        body_html += "</table><br><p><i>‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ JobThai Scraper (Google Sheets Edition)</i></p></body></html>"

        try:
            server = smtplib.SMTP('smtp.gmail.com', 587)
            server.starttls()
            server.login(sender, password)
            
            msg_root = MIMEMultipart('related')
            msg_root['From'] = sender
            msg_root['Subject'] = subject
            
            msg_alternative = MIMEMultipart('alternative')
            msg_root.attach(msg_alternative)
            msg_alternative.attach(MIMEText(body_html, 'html'))
            
            for img_data in images_to_attach:
                try:
                    with open(img_data['path'], 'rb') as f:
                        msg_img = MIMEImage(f.read())
                        msg_img.add_header('Content-ID', f"<{img_data['cid']}>")
                        msg_img.add_header('Content-Disposition', 'inline', filename=os.path.basename(img_data['path']))
                        msg_root.attach(msg_img)
                except: pass

            for rec in receiver_list:
                if 'To' in msg_root: del msg_root['To']
                msg_root['To'] = rec
                server.send_message(msg_root)
                console.print(f"   ‚úÖ ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏• '{subject}' -> {rec}", style="success")
            server.quit()
        except Exception as e:
            console.print(f"‚ùå ‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {e}", style="error")

    def send_batch_email(self, batch_candidates, keyword):
        self.send_single_email(f"‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏£‡∏≤‡∏¢‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå: {keyword} ({len(batch_candidates)} ‡∏Ñ‡∏ô)", batch_candidates)

    # üü¢ [CORE FEATURE] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏∂‡πâ‡∏ô Google Sheets
    def save_to_google_sheets(self):
        if not self.all_scraped_data:
            console.print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å", style="yellow")
            return

        console.rule("[bold green]üìä ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏∂‡πâ‡∏ô Google Sheets[/]")
        
        # 1. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ API
        try:
            if not G_SHEET_KEY_JSON or not G_SHEET_NAME:
                console.print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Key ‡∏´‡∏£‡∏∑‡∏≠‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå Google Sheet ‡πÉ‡∏ô Secrets", style="error")
                return

            creds_dict = json.loads(G_SHEET_KEY_JSON)
            scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
            creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
            client = gspread.authorize(creds)
            
            # 2. ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå Sheet
            sheet = client.open(G_SHEET_NAME)
            console.print(f"‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå '{G_SHEET_NAME}' ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à", style="success")
            
            # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Tab ‡∏ä‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô (DD-MM-YYYY)
            today_str = datetime.datetime.now().strftime("%d-%m-%Y")
            try:
                worksheet = sheet.worksheet(today_str)
                console.print(f"‚ÑπÔ∏è ‡∏û‡∏ö Tab '{today_str}' ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß -> ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡πà‡∏≠‡∏ó‡πâ‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Append)", style="info")
            except:
                worksheet = sheet.add_worksheet(title=today_str, rows="100", cols="20")
                console.print(f"üÜï ‡∏™‡∏£‡πâ‡∏≤‡∏á Tab ‡πÉ‡∏´‡∏°‡πà: '{today_str}'", style="success")
                
                # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô Header (üü¢ ‡πÄ‡∏û‡∏¥‡πà‡∏° Min/Max)
                headers = [
                    "Link", "Keyword", "‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£", "‡∏ä‡∏∑‡πà‡∏≠-‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•", "‡∏≠‡∏≤‡∏¢‡∏∏", "‡πÄ‡∏û‡∏®", 
                    "‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£", "Email", "‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà", "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤", "‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢", "‡∏Ñ‡∏ì‡∏∞", "‡∏™‡∏≤‡∏Ç‡∏≤",
                    "‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏±‡∏Ñ‡∏£", "‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠ (Raw)", "‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î", "‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î", # üü¢ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
                    "‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á", "‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î"
                ]
                worksheet.append_row(headers)

            # 4. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î (Data Cleaning)
            data_rows = []
            for item in self.all_scraped_data:
                # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Header
                row = [
                    item.get('Link', ''),
                    item.get('Keyword', ''),
                    item.get('‡∏£‡∏´‡∏±‡∏™‡πÉ‡∏ö‡∏™‡∏°‡∏±‡∏Ñ‡∏£', ''),
                    f"{item.get('‡∏ä‡∏∑‡πà‡∏≠','')} {item.get('‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•','')}",
                    item.get('‡∏≠‡∏≤‡∏¢‡∏∏', ''),
                    item.get('‡πÄ‡∏û‡∏®', ''),
                    re.sub(r'\D', '', str(item.get('‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÇ‡∏ó‡∏£', ''))),
                    str(item.get('Email', '')).replace('Click', '').strip(),
                    item.get('‡∏à‡∏±‡∏á‡∏´‡∏ß‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà', ''),
                    item.get('‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤', ''),
                    item.get('‡∏°‡∏´‡∏≤‡∏•‡∏±‡∏¢', ''),
                    item.get('‡∏Ñ‡∏ì‡∏∞', ''),
                    item.get('‡∏™‡∏≤‡∏Ç‡∏≤', ''),
                    f"{item.get('‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_1','')} {item.get('‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏±‡∏Ñ‡∏£_2','')}",
                    item.get('‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£', ''),
                    item.get('Salary_Min', '-'), # üü¢ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
                    item.get('Salary_Max', '-'), # üü¢ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
                    item.get('‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó‡∏Ñ‡∏π‡πà‡πÅ‡∏Ç‡πà‡∏á', ''),
                    item.get('‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î', '')
                ]
                data_rows.append(row)
            
            # 5. ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (Batch Upload)
            if data_rows:
                worksheet.append_rows(data_rows)
                console.print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(data_rows)} ‡πÅ‡∏ñ‡∏ß ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢!", style="bold green")
                
        except Exception as e:
            console.print(f"‚ùå Google Sheets Error: {e}", style="error")

    def run(self):
        self.email_report_list = []
        if not self.step1_login(): return
        
        today = datetime.date.today()
        is_monday = (today.weekday() == 0)
        is_manual_run = (os.getenv("GITHUB_EVENT_NAME") == "workflow_dispatch")
        
        console.print(f"üìÖ Status Check: Today is Monday? [{'Yes' if is_monday else 'No'}] | Manual Run? [{'Yes' if is_manual_run else 'No'}]", style="bold yellow")
        
        master_data_list = [] 
        
        for index, keyword in enumerate(SEARCH_KEYWORDS):
            console.rule(f"[bold magenta]üîç ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏ó‡∏µ‡πà {index+1}/{len(SEARCH_KEYWORDS)}: {keyword}[/]")
            
            current_keyword_batch = []
            if self.step2_search(keyword):
                links = self.step3_collect_all_links()
                if links:
                    console.print(f"\nüöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏π‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö '{keyword}' ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô {len(links)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ ...")
                    with Progress(
                        SpinnerColumn(), TextColumn("[progress.description]{task.description}"),
                        BarColumn(), TaskProgressColumn(), TimeElapsedColumn(), TimeRemainingColumn(),
                        console=console
                    ) as progress:
                        task_id = progress.add_task(f"[cyan]Processing {keyword}...", total=len(links))
                        
                        for i, link in enumerate(links):
                            if self.total_profiles_viewed > 0 and self.total_profiles_viewed % 33 == 0:
                                progress.console.print(f"[yellow]‚òï ‡∏Ñ‡∏£‡∏ö {self.total_profiles_viewed} ‡∏Ñ‡∏ô‡πÅ‡∏•‡πâ‡∏ß... ‡∏û‡∏±‡∏Å‡πÄ‡∏ö‡∏£‡∏Å 4 ‡∏ô‡∏≤‡∏ó‡∏µ[/]")
                                time.sleep(240)

                            try:
                                d, days_diff, person_data = self.scrape_detail_from_json(link, keyword, progress_console=progress.console)
                                self.total_profiles_viewed += 1 
                                
                                if d is not None:
                                    d['Keyword'] = keyword
                                    
                                    # üü¢ 1. ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ List ‡πÉ‡∏´‡∏ç‡πà (‡∏£‡∏≠ Save ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡∏à‡∏ö)
                                    self.all_scraped_data.append(d)
                                    
                                    # --- Logic ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏• (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°) ---
                                    should_add = False
                                    if days_diff <= 30:
                                        should_add = True
                                        if EMAIL_USE_HISTORY and person_data['id'] in self.history_data:
                                            try:
                                                last_notify = datetime.datetime.strptime(self.history_data[person_data['id']], "%Y-%m-%d").date()
                                                if (today - last_notify).days < 7: should_add = False
                                            except: pass
                                        if should_add: current_keyword_batch.append(person_data)

                                    if days_diff <= 1:
                                        should_hot = True
                                        if EMAIL_USE_HISTORY and person_data['id'] in self.history_data:
                                             try:
                                                last_notify = datetime.datetime.strptime(self.history_data[person_data['id']], "%Y-%m-%d").date()
                                                if (today - last_notify).days < 1: should_hot = False
                                             except: pass
                                        if should_hot:
                                            hot_subject = f"üî• [HOT] ‡∏û‡∏ö‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£‡∏î‡πà‡∏ß‡∏ô ({keyword}): {person_data['name']}"
                                            progress.console.print(f"   üö® ‡∏û‡∏ö‡∏ú‡∏π‡πâ‡∏™‡∏°‡∏±‡∏Ñ‡∏£ HOT -> ‡∏™‡πà‡∏á‡πÄ‡∏°‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ!", style="bold red")
                                            self.send_single_email(hot_subject, [person_data], col_header="‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó")
                                            if EMAIL_USE_HISTORY: self.history_data[person_data['id']] = str(today)

                                    if days_diff > 30 and (is_monday or is_manual_run):
                                        if current_keyword_batch:
                                             progress.console.print(f"\n[bold green]üì® ‡πÄ‡∏à‡∏≠‡∏Ñ‡∏ô‡πÄ‡∏Å‡πà‡∏≤ ({days_diff} ‡∏ß‡∏±‡∏ô) -> ‡∏ñ‡∏∂‡∏á‡∏£‡∏≠‡∏ö‡∏™‡πà‡∏á‡πÄ‡∏°‡∏•‡∏™‡∏£‡∏∏‡∏õ ({len(current_keyword_batch)} ‡∏Ñ‡∏ô)![/]")
                                             self.send_batch_email(current_keyword_batch, keyword)
                                             if EMAIL_USE_HISTORY:
                                                for p in current_keyword_batch: self.history_data[p['id']] = str(today)
                                             current_keyword_batch = []

                            except Exception as e: progress.console.print(f"[bold red]‚ùå Error Link {i+1}: {e}[/]")
                            progress.advance(task_id)
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏Å‡πÄ‡∏°‡∏• Batch
                if current_keyword_batch and (is_monday or is_manual_run):
                    self.send_batch_email(current_keyword_batch, keyword)
                    if EMAIL_USE_HISTORY:
                         for p in current_keyword_batch: self.history_data[p['id']] = str(today)

            console.print("‚è≥ ‡∏û‡∏±‡∏Å 3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ï‡πà‡∏≠‡πÑ‡∏õ...", style="dim")
            time.sleep(3)
        
        # üü¢ ‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏∂‡πâ‡∏ô Google Sheets ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ï‡∏≠‡∏ô‡∏à‡∏ö
        self.save_to_google_sheets()
        
        self.save_history()
        console.rule("[bold green]üèÅ ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô JobThai (Google Sheets Mode)[/]")
        try: self.driver.quit()
        except: pass

if __name__ == "__main__":
    console.print("[bold green]üöÄ Starting JobThai Scraper (Google Sheets Edition)...[/]")
    if not MY_USERNAME or not MY_PASSWORD:
        console.print(f"\n[bold red]‚ùå [CRITICAL ERROR] ‡πÑ‡∏°‡πà‡∏û‡∏ö User/Pass ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå .env[/]")
        exit()
    scraper = JobThaiRowScraper()
    scraper.run()
